{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af9a5912-2d74-414d-a5d6-54ead44877f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/anjana/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anjana/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/anjana/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /home/anjana/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/anjana/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c1da5-016e-4a32-ab56-9a4b98ff72f3",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73fb9cdb-1f8e-4784-9b50-4c27ed74fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cricket',\n",
       " 'is',\n",
       " 'a',\n",
       " 'popular',\n",
       " 'game',\n",
       " 'in',\n",
       " 'many',\n",
       " 'countries',\n",
       " '.',\n",
       " 'People',\n",
       " 'love',\n",
       " 'watching',\n",
       " 'cricket',\n",
       " 'matches',\n",
       " 'and',\n",
       " 'cheering',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teams',\n",
       " '.',\n",
       " 'Cricket',\n",
       " 'players',\n",
       " 'train',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'win',\n",
       " 'tournaments',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cricket = \"Cricket is a popular game in many countries. People love watching cricket matches and cheering for their teams. Cricket players train hard to win tournaments.\"\n",
    "cricket_tokens = word_tokenize(cricket)\n",
    "cricket_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c4cdf8f-4b34-4de7-9a4f-943f57cd9f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cricket_tokens), len(cricket_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d823da45-1dbe-4aed-9d4a-142650213f84",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a9104a-f52f-40e1-9bc7-f97e9543231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed3c2e1-432b-4733-8ee2-d419c0c65f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 6, 'Cricket': 4, 'is': 2, 'a': 2, 'popular': 2, 'game': 2, 'in': 2, 'many': 2, 'countries': 2, 'People': 2, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in cricket_tokens:\n",
    "    fdist[i] = fdist[i]+1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbfcba86-2a9d-4f6b-a838-90e7c258438b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 6),\n",
       " ('Cricket', 4),\n",
       " ('is', 2),\n",
       " ('a', 2),\n",
       " ('popular', 2),\n",
       " ('game', 2),\n",
       " ('in', 2),\n",
       " ('many', 2),\n",
       " ('countries', 2),\n",
       " ('People', 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = fdist.most_common(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab816ca6-3395-417b-bb7a-28973b89e7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cricket', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'popular'),\n",
       " ('popular', 'game'),\n",
       " ('game', 'in'),\n",
       " ('in', 'many'),\n",
       " ('many', 'countries'),\n",
       " ('countries', '.'),\n",
       " ('.', 'People'),\n",
       " ('People', 'love'),\n",
       " ('love', 'watching'),\n",
       " ('watching', 'cricket'),\n",
       " ('cricket', 'matches'),\n",
       " ('matches', 'and'),\n",
       " ('and', 'cheering'),\n",
       " ('cheering', 'for'),\n",
       " ('for', 'their'),\n",
       " ('their', 'teams'),\n",
       " ('teams', '.'),\n",
       " ('.', 'Cricket'),\n",
       " ('Cricket', 'players'),\n",
       " ('players', 'train'),\n",
       " ('train', 'hard'),\n",
       " ('hard', 'to'),\n",
       " ('to', 'win'),\n",
       " ('win', 'tournaments'),\n",
       " ('tournaments', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(cricket_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28822b4b-4e06-432d-85ff-84d1d348b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cricket', 'is', 'a'),\n",
       " ('is', 'a', 'popular'),\n",
       " ('a', 'popular', 'game'),\n",
       " ('popular', 'game', 'in'),\n",
       " ('game', 'in', 'many'),\n",
       " ('in', 'many', 'countries'),\n",
       " ('many', 'countries', '.'),\n",
       " ('countries', '.', 'People'),\n",
       " ('.', 'People', 'love'),\n",
       " ('People', 'love', 'watching'),\n",
       " ('love', 'watching', 'cricket'),\n",
       " ('watching', 'cricket', 'matches'),\n",
       " ('cricket', 'matches', 'and'),\n",
       " ('matches', 'and', 'cheering'),\n",
       " ('and', 'cheering', 'for'),\n",
       " ('cheering', 'for', 'their'),\n",
       " ('for', 'their', 'teams'),\n",
       " ('their', 'teams', '.'),\n",
       " ('teams', '.', 'Cricket'),\n",
       " ('.', 'Cricket', 'players'),\n",
       " ('Cricket', 'players', 'train'),\n",
       " ('players', 'train', 'hard'),\n",
       " ('train', 'hard', 'to'),\n",
       " ('hard', 'to', 'win'),\n",
       " ('to', 'win', 'tournaments'),\n",
       " ('win', 'tournaments', '.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(cricket_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9dfa4c9-5341-429f-a8d9-050ddae9602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cricket', 'is', 'a', 'popular'),\n",
       " ('is', 'a', 'popular', 'game'),\n",
       " ('a', 'popular', 'game', 'in'),\n",
       " ('popular', 'game', 'in', 'many'),\n",
       " ('game', 'in', 'many', 'countries'),\n",
       " ('in', 'many', 'countries', '.'),\n",
       " ('many', 'countries', '.', 'People'),\n",
       " ('countries', '.', 'People', 'love'),\n",
       " ('.', 'People', 'love', 'watching'),\n",
       " ('People', 'love', 'watching', 'cricket'),\n",
       " ('love', 'watching', 'cricket', 'matches'),\n",
       " ('watching', 'cricket', 'matches', 'and'),\n",
       " ('cricket', 'matches', 'and', 'cheering'),\n",
       " ('matches', 'and', 'cheering', 'for'),\n",
       " ('and', 'cheering', 'for', 'their'),\n",
       " ('cheering', 'for', 'their', 'teams'),\n",
       " ('for', 'their', 'teams', '.'),\n",
       " ('their', 'teams', '.', 'Cricket'),\n",
       " ('teams', '.', 'Cricket', 'players'),\n",
       " ('.', 'Cricket', 'players', 'train'),\n",
       " ('Cricket', 'players', 'train', 'hard'),\n",
       " ('players', 'train', 'hard', 'to'),\n",
       " ('train', 'hard', 'to', 'win'),\n",
       " ('hard', 'to', 'win', 'tournaments'),\n",
       " ('to', 'win', 'tournaments', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(cricket_tokens, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfeb7f-cb5a-4c52-84f0-bdf0066d093e",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3e4ee05-85fe-452b-882f-73977453b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('win', 'studi', 'buy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "pst.stem('winning'), pst.stem('studied'), pst.stem('buying')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2b651-401a-4b7a-8d1c-a34ceec3d722",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dee67f3e-5cfe-4ad4-87a8-c5c6a774895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats:cat\n",
      "cacti:cactus\n",
      "geese:goose\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['cats', 'cacti', 'geese']\n",
    "for i in words:\n",
    "    print(i +':'+lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c4098-94e5-466a-82fe-55dcfc0aef06",
   "metadata": {},
   "source": [
    "### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfa8a674-8acb-48bd-b7ab-740e9885ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP')]\n",
      "[('do', 'VB')]\n",
      "[('you', 'PRP')]\n",
      "[('mean', 'NN')]\n",
      "[(',', ',')]\n",
      "[('I', 'PRP')]\n",
      "[('dont', 'NN')]\n",
      "[('believe', 'VB')]\n",
      "[('in', 'IN')]\n",
      "[('God', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "sen = 'What do you mean , I dont believe in God'\n",
    "sen_tok = word_tokenize(sen)\n",
    "for i in sen_tok:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202cd58-bdf7-4c56-82c8-4b42723e40e4",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a513b1b-19f9-409d-82a8-8eebdd074902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'), ('lives', 'VBZ'), ('in', 'IN'), ('India', 'NNP')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "sen = 'John lives in India'\n",
    "sen_tok = word_tokenize(sen)\n",
    "sen_pos = nltk.pos_tag(sen_tok)\n",
    "sen_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a3a2ebf-cef0-46b7-bf9c-516e793db851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S                     \n",
      "     _______|________________      \n",
      "    |       |    PERSON     GPE   \n",
      "    |       |      |         |     \n",
      "lives/VBZ in/IN John/NNP India/NNP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_ne = ne_chunk(sen_pos)\n",
    "sen_ne.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea74a18-e00e-4eeb-ad6a-198207d09429",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fdf6509-55ed-4aca-95b0-46b642e761aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a1ffa4f-f96e-4ca2-9375-9e46f907d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "to\n",
      "buy\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "1\n",
      "$\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is looking to buy U.K. startup for 1$ billion')\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6f7debe-23b5-4989-87fd-6a6a4bb5754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "looking"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[2]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31e1a4f6-2886-4900-a797-237335dc3a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "looking to buy"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[2:5]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e32eeaf-c9ef-4e7b-a53f-eb085721374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Apple\n",
      "PROPN\n",
      "1 is\n",
      "AUX\n",
      "2 looking\n",
      "VERB\n",
      "3 to\n",
      "PART\n",
      "4 buy\n",
      "VERB\n",
      "5 U.K.\n",
      "PROPN\n",
      "6 startup\n",
      "NOUN\n",
      "7 for\n",
      "ADP\n",
      "8 1\n",
      "NUM\n",
      "9 $\n",
      "SYM\n",
      "10 billion\n",
      "NUM\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.i, token.text)\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4f5d952-8c90-486b-9edb-ec9c9aa7f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "1$ billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "630540a6-4fd1-45ac-b4c2-c59650d35712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacating white\n"
     ]
    }
   ],
   "source": [
    "# Matcher\n",
    "from spacy.matcher  import Matcher\n",
    "doc = nlp('Barack Obama the former president of United States will be vacating white house today')\n",
    "\n",
    "pattern = [{'LEMMA':'vacate'}, {'ORTH':'white'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('white_pattern', [pattern])\n",
    "matches =matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04c868-d627-4a1f-a850-6038950b7a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb71cb1-eec5-4449-b00e-d5184b80ad86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448125d-2fed-4657-b89d-27780a553e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
